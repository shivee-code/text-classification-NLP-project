# -*- coding: utf-8 -*-
"""Text Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sh23j4TSkItpW5WNHR8gsygNb2FC0ymm

**Preparing the Data for Text Classification**

This section covers the steps for loading, preprocessing, and transforming the raw text data into a format suitable for training and evaluating machine learning models
"""

# Importing necessariey libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

# Step 1: Create the dataset

data = {
    'Review':[
        "This product is amazing, I love it!",
        "Wrost purchase I've ever made, completely disappointed.",
        "It's okay, not bad but not great either.",
        "The quality is fantastic, will definitely buy again.",
        "Terrible. Stopped working after a week.",
        "satisfactory, does the job well.",
        "Excellent value for money. Highly recmmended!",
        "Not what I expected, very poor quality.",
        "Decent quality for the price.",
        "Loved the product. Worth every penny."
    ],
    'Sentiment':[
        'Positive', 'Negative', 'Neutral', 'Positive', 'Negative', 'Neutral',
        'Positive', 'Negative', 'Neutral', 'Positive'
    ]
}

# Coverting the data into DataFrame
df = pd.DataFrame(data)

df

# Step 2: Preprocessingthe text data

# Creating text to lowercase
df['Review'] = df['Review'].str.lower()

# Remove stopwords
stop_words = stopwords.words('english')
df['Review'] = df['Review'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))

# Step 3: Splitting the dataset into training and testing sets
X = df['Review']     # Features (text reviews)
y = df['Sentiment']  # Labels (sentiment)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Vectorization (Convert text to numerical data using TF-IDF)
vectorizer = TfidfVectorizer()
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

"""**Building a Text Classification Model**"""

from sklearn.svm import SVC
from sklearn.metrics import classification_report
from nltk.tokenize import word_tokenize     # Import word_tokenize

# Step 5: Train an SVM classification
model = SVC(kernel='linear', random_state=42)
model.fit(X_train_tfidf, y_train)

# Step 6:
def predict_sentiment(new_reviews):
  # Preparing the new reviews
  preprocessed_reviews = [
      ' '.join([word for word in word_tokenize(review.lower)() if word.isalpha() and word not in stopword])
      for review in new_reviews
  ]

  # Transform the reviews using the vectorizer
  reviews_tfidf = vectorizer.transform(preprocessed_reviews)

  # Predict sentiment
  predictions = model.predict(reviews_tfidf)
  return predictions

# Step 7: Request user input for reviews
print("Please enter a review to classify its sentiment (type 'exit' to stop):")

while True:
  # Take input from the user
  user_input = input("Enter Review: ")

  # If user types 'exit', break out of the loop
  if user_input.lower() == 'exit':
    print("Exiting program.")
    break

  # Predict sentiment for the entered review

  predicted_sentiment = predict_sentiment([user_input])

  # Display prediction
  print(f"Review: {user_input}\nPredicted Sentiment: {predicted_sentiment[0]}\n")